{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01. Tip on checking different functions in Python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLLb9D1S+pWTb/ErZ1feC/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJLkKkpQhoul",
        "outputId": "f28cbac0-1981-45da-e252-16c22c8db39b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas #installing package"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #importing library"
      ],
      "metadata": {
        "id": "Nk2JzcEnh7hN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(pd)\n",
        "\n",
        "#dir() is a powerful inbuilt function in Python3, which returns list of the attributes\n",
        "#and methods of any object (say functions , modules, strings, lists, dictionaries etc.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sibPaN-RiUEw",
        "outputId": "edfb1b1e-be87-4f88-b451-b93f1fbc05f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BooleanDtype',\n",
              " 'Categorical',\n",
              " 'CategoricalDtype',\n",
              " 'CategoricalIndex',\n",
              " 'DataFrame',\n",
              " 'DateOffset',\n",
              " 'DatetimeIndex',\n",
              " 'DatetimeTZDtype',\n",
              " 'ExcelFile',\n",
              " 'ExcelWriter',\n",
              " 'Flags',\n",
              " 'Float32Dtype',\n",
              " 'Float64Dtype',\n",
              " 'Float64Index',\n",
              " 'Grouper',\n",
              " 'HDFStore',\n",
              " 'Index',\n",
              " 'IndexSlice',\n",
              " 'Int16Dtype',\n",
              " 'Int32Dtype',\n",
              " 'Int64Dtype',\n",
              " 'Int64Index',\n",
              " 'Int8Dtype',\n",
              " 'Interval',\n",
              " 'IntervalDtype',\n",
              " 'IntervalIndex',\n",
              " 'MultiIndex',\n",
              " 'NA',\n",
              " 'NaT',\n",
              " 'NamedAgg',\n",
              " 'Period',\n",
              " 'PeriodDtype',\n",
              " 'PeriodIndex',\n",
              " 'RangeIndex',\n",
              " 'Series',\n",
              " 'SparseDtype',\n",
              " 'StringDtype',\n",
              " 'Timedelta',\n",
              " 'TimedeltaIndex',\n",
              " 'Timestamp',\n",
              " 'UInt16Dtype',\n",
              " 'UInt32Dtype',\n",
              " 'UInt64Dtype',\n",
              " 'UInt64Index',\n",
              " 'UInt8Dtype',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__docformat__',\n",
              " '__file__',\n",
              " '__getattr__',\n",
              " '__git_version__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__version__',\n",
              " '_config',\n",
              " '_hashtable',\n",
              " '_is_numpy_dev',\n",
              " '_lib',\n",
              " '_libs',\n",
              " '_np_version_under1p18',\n",
              " '_testing',\n",
              " '_tslib',\n",
              " '_typing',\n",
              " '_version',\n",
              " 'api',\n",
              " 'array',\n",
              " 'arrays',\n",
              " 'bdate_range',\n",
              " 'compat',\n",
              " 'concat',\n",
              " 'core',\n",
              " 'crosstab',\n",
              " 'cut',\n",
              " 'date_range',\n",
              " 'describe_option',\n",
              " 'errors',\n",
              " 'eval',\n",
              " 'factorize',\n",
              " 'get_dummies',\n",
              " 'get_option',\n",
              " 'infer_freq',\n",
              " 'interval_range',\n",
              " 'io',\n",
              " 'isna',\n",
              " 'isnull',\n",
              " 'json_normalize',\n",
              " 'lreshape',\n",
              " 'melt',\n",
              " 'merge',\n",
              " 'merge_asof',\n",
              " 'merge_ordered',\n",
              " 'notna',\n",
              " 'notnull',\n",
              " 'offsets',\n",
              " 'option_context',\n",
              " 'options',\n",
              " 'pandas',\n",
              " 'period_range',\n",
              " 'pivot',\n",
              " 'pivot_table',\n",
              " 'plotting',\n",
              " 'qcut',\n",
              " 'read_clipboard',\n",
              " 'read_csv',\n",
              " 'read_excel',\n",
              " 'read_feather',\n",
              " 'read_fwf',\n",
              " 'read_gbq',\n",
              " 'read_hdf',\n",
              " 'read_html',\n",
              " 'read_json',\n",
              " 'read_orc',\n",
              " 'read_parquet',\n",
              " 'read_pickle',\n",
              " 'read_sas',\n",
              " 'read_spss',\n",
              " 'read_sql',\n",
              " 'read_sql_query',\n",
              " 'read_sql_table',\n",
              " 'read_stata',\n",
              " 'read_table',\n",
              " 'read_xml',\n",
              " 'reset_option',\n",
              " 'set_eng_float_format',\n",
              " 'set_option',\n",
              " 'show_versions',\n",
              " 'test',\n",
              " 'testing',\n",
              " 'timedelta_range',\n",
              " 'to_datetime',\n",
              " 'to_numeric',\n",
              " 'to_pickle',\n",
              " 'to_timedelta',\n",
              " 'tseries',\n",
              " 'unique',\n",
              " 'util',\n",
              " 'value_counts',\n",
              " 'wide_to_long']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(pd.concat) #help function is used to display the documentation of modules, functions, classes, keywords, etc. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk7CYe1NiXjr",
        "outputId": "ff85bcaa-887a-4123-8706-e6c1edebade4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function concat in module pandas.core.reshape.concat:\n",
            "\n",
            "concat(objs: 'Iterable[NDFrame] | Mapping[Hashable, NDFrame]', axis=0, join='outer', ignore_index: 'bool' = False, keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, copy: 'bool' = True) -> 'FrameOrSeriesUnion'\n",
            "    Concatenate pandas objects along a particular axis with optional set logic\n",
            "    along the other axes.\n",
            "    \n",
            "    Can also add a layer of hierarchical indexing on the concatenation axis,\n",
            "    which may be useful if the labels are the same (or overlapping) on\n",
            "    the passed axis number.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    objs : a sequence or mapping of Series or DataFrame objects\n",
            "        If a mapping is passed, the sorted keys will be used as the `keys`\n",
            "        argument, unless it is passed, in which case the values will be\n",
            "        selected (see below). Any None objects will be dropped silently unless\n",
            "        they are all None in which case a ValueError will be raised.\n",
            "    axis : {0/'index', 1/'columns'}, default 0\n",
            "        The axis to concatenate along.\n",
            "    join : {'inner', 'outer'}, default 'outer'\n",
            "        How to handle indexes on other axis (or axes).\n",
            "    ignore_index : bool, default False\n",
            "        If True, do not use the index values along the concatenation axis. The\n",
            "        resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
            "        concatenating objects where the concatenation axis does not have\n",
            "        meaningful indexing information. Note the index values on the other\n",
            "        axes are still respected in the join.\n",
            "    keys : sequence, default None\n",
            "        If multiple levels passed, should contain tuples. Construct\n",
            "        hierarchical index using the passed keys as the outermost level.\n",
            "    levels : list of sequences, default None\n",
            "        Specific levels (unique values) to use for constructing a\n",
            "        MultiIndex. Otherwise they will be inferred from the keys.\n",
            "    names : list, default None\n",
            "        Names for the levels in the resulting hierarchical index.\n",
            "    verify_integrity : bool, default False\n",
            "        Check whether the new concatenated axis contains duplicates. This can\n",
            "        be very expensive relative to the actual data concatenation.\n",
            "    sort : bool, default False\n",
            "        Sort non-concatenation axis if it is not already aligned when `join`\n",
            "        is 'outer'.\n",
            "        This has no effect when ``join='inner'``, which already preserves\n",
            "        the order of the non-concatenation axis.\n",
            "    \n",
            "        .. versionchanged:: 1.0.0\n",
            "    \n",
            "           Changed to not sort by default.\n",
            "    \n",
            "    copy : bool, default True\n",
            "        If False, do not copy data unnecessarily.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    object, type of objs\n",
            "        When concatenating all ``Series`` along the index (axis=0), a\n",
            "        ``Series`` is returned. When ``objs`` contains at least one\n",
            "        ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n",
            "        the columns (axis=1), a ``DataFrame`` is returned.\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    Series.append : Concatenate Series.\n",
            "    DataFrame.append : Concatenate DataFrames.\n",
            "    DataFrame.join : Join DataFrames using indexes.\n",
            "    DataFrame.merge : Merge DataFrames by indexes or columns.\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    The keys, levels, and names arguments are all optional.\n",
            "    \n",
            "    A walkthrough of how this method fits in with other tools for combining\n",
            "    pandas objects can be found `here\n",
            "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    Combine two ``Series``.\n",
            "    \n",
            "    >>> s1 = pd.Series(['a', 'b'])\n",
            "    >>> s2 = pd.Series(['c', 'd'])\n",
            "    >>> pd.concat([s1, s2])\n",
            "    0    a\n",
            "    1    b\n",
            "    0    c\n",
            "    1    d\n",
            "    dtype: object\n",
            "    \n",
            "    Clear the existing index and reset it in the result\n",
            "    by setting the ``ignore_index`` option to ``True``.\n",
            "    \n",
            "    >>> pd.concat([s1, s2], ignore_index=True)\n",
            "    0    a\n",
            "    1    b\n",
            "    2    c\n",
            "    3    d\n",
            "    dtype: object\n",
            "    \n",
            "    Add a hierarchical index at the outermost level of\n",
            "    the data with the ``keys`` option.\n",
            "    \n",
            "    >>> pd.concat([s1, s2], keys=['s1', 's2'])\n",
            "    s1  0    a\n",
            "        1    b\n",
            "    s2  0    c\n",
            "        1    d\n",
            "    dtype: object\n",
            "    \n",
            "    Label the index keys you create with the ``names`` option.\n",
            "    \n",
            "    >>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
            "    ...           names=['Series name', 'Row ID'])\n",
            "    Series name  Row ID\n",
            "    s1           0         a\n",
            "                 1         b\n",
            "    s2           0         c\n",
            "                 1         d\n",
            "    dtype: object\n",
            "    \n",
            "    Combine two ``DataFrame`` objects with identical columns.\n",
            "    \n",
            "    >>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
            "    ...                    columns=['letter', 'number'])\n",
            "    >>> df1\n",
            "      letter  number\n",
            "    0      a       1\n",
            "    1      b       2\n",
            "    >>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
            "    ...                    columns=['letter', 'number'])\n",
            "    >>> df2\n",
            "      letter  number\n",
            "    0      c       3\n",
            "    1      d       4\n",
            "    >>> pd.concat([df1, df2])\n",
            "      letter  number\n",
            "    0      a       1\n",
            "    1      b       2\n",
            "    0      c       3\n",
            "    1      d       4\n",
            "    \n",
            "    Combine ``DataFrame`` objects with overlapping columns\n",
            "    and return everything. Columns outside the intersection will\n",
            "    be filled with ``NaN`` values.\n",
            "    \n",
            "    >>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
            "    ...                    columns=['letter', 'number', 'animal'])\n",
            "    >>> df3\n",
            "      letter  number animal\n",
            "    0      c       3    cat\n",
            "    1      d       4    dog\n",
            "    >>> pd.concat([df1, df3], sort=False)\n",
            "      letter  number animal\n",
            "    0      a       1    NaN\n",
            "    1      b       2    NaN\n",
            "    0      c       3    cat\n",
            "    1      d       4    dog\n",
            "    \n",
            "    Combine ``DataFrame`` objects with overlapping columns\n",
            "    and return only those that are shared by passing ``inner`` to\n",
            "    the ``join`` keyword argument.\n",
            "    \n",
            "    >>> pd.concat([df1, df3], join=\"inner\")\n",
            "      letter  number\n",
            "    0      a       1\n",
            "    1      b       2\n",
            "    0      c       3\n",
            "    1      d       4\n",
            "    \n",
            "    Combine ``DataFrame`` objects horizontally along the x axis by\n",
            "    passing in ``axis=1``.\n",
            "    \n",
            "    >>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
            "    ...                    columns=['animal', 'name'])\n",
            "    >>> pd.concat([df1, df4], axis=1)\n",
            "      letter  number  animal    name\n",
            "    0      a       1    bird   polly\n",
            "    1      b       2  monkey  george\n",
            "    \n",
            "    Prevent the result from including duplicate index values with the\n",
            "    ``verify_integrity`` option.\n",
            "    \n",
            "    >>> df5 = pd.DataFrame([1], index=['a'])\n",
            "    >>> df5\n",
            "       0\n",
            "    a  1\n",
            "    >>> df6 = pd.DataFrame([2], index=['a'])\n",
            "    >>> df6\n",
            "       0\n",
            "    a  2\n",
            "    >>> pd.concat([df5, df6], verify_integrity=True)\n",
            "    Traceback (most recent call last):\n",
            "        ...\n",
            "    ValueError: Indexes have overlapping values: ['a']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EndOfCode"
      ],
      "metadata": {
        "id": "AhPrbUrYiqbj"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}